{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAdPrfekPPSl4EeUmL8Rer",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablobermudez/Up/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUOT0TsOoDzz"
      },
      "source": [
        "#2 Armado del ambiente\n",
        "Instalar en el cuaderno el módulo CUDA de Python.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eceh5yt8oQ1y"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxAHGanvpPnI"
      },
      "source": [
        "#3 Desarrollo - CPU\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTlmmqpspVZY"
      },
      "source": [
        "\n",
        "from datetime import datetime\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "arr = np.round([random.uniform(1,10) for _ in range(1000)], decimals=2)\n",
        "\n",
        "\n",
        "def bubbleSort(arr): \n",
        "    n = len(arr) \n",
        "\n",
        "    for i in range(n-1): \n",
        "        for j in range(0, n-i-1): \n",
        "            if arr[j] > arr[j+1] : \n",
        "                arr[j], arr[j+1] = arr[j+1], arr[j] \n",
        "  \n",
        "  \n",
        "bubbleSort(arr) \n",
        "print(arr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai2DT1HitKMn"
      },
      "source": [
        "#3 Desarrollo - GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds_geZIJtLtI",
        "outputId": "979919e6-2922-46b8-e298-4984c8f28fa1"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "cantidad_N =   50000#@param {type: \"number\"}\n",
        "alfa =   1#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import numpy\n",
        "\n",
        "# --------------------------------------------\n",
        "# Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "\n",
        "# CPU - Defino la memoria de los vectores en cpu.\n",
        "x_cpu = numpy.random.randn( cantidad_N )\n",
        "x_cpu = x_cpu.astype( numpy.float32() )\n",
        "\n",
        "y_cpu = numpy.random.randn( cantidad_N )\n",
        "y_cpu = y_cpu.astype( numpy.float32() )\n",
        "\n",
        "#tiempo_ini_cpu = datetime.now()\n",
        "\n",
        "r_cpu = numpy.empty_like( x_cpu )\n",
        "\n",
        "# CPU - reservo la memoria GPU.\n",
        "x_gpu = cuda.mem_alloc( x_cpu.nbytes )\n",
        "y_gpu = cuda.mem_alloc( y_cpu.nbytes )\n",
        "\n",
        "# GPU - Copio la memoria al GPU.\n",
        "cuda.memcpy_htod( x_gpu, x_cpu )\n",
        "cuda.memcpy_htod( y_gpu, y_cpu )\n",
        "\n",
        "# CPU - Defino la función kernel que ejecutará en GPU.\n",
        "module = SourceModule(\"\"\"\n",
        "#include <stdio.h>\n",
        "__global__ void kernel_axpy( int n, float alfa, float *X, float *Y )\n",
        "{\n",
        "  int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  if( idx < n )\n",
        "  {\n",
        "     printf(\"I am %d.%d\\\\n\", threadIdx.x, threadIdx.y);\n",
        "    Y[idx]  = alfa*X[idx] + Y[idx];\n",
        "  }\n",
        "  \n",
        "}\n",
        "\"\"\") \n",
        "# CPU - Genero la función kernel.\n",
        "kernel = module.get_function(\"kernel_axpy\")\n",
        "\n",
        "tiempo_gpu = datetime.now()\n",
        "\n",
        "# GPU - Ejecuta el kernel.\n",
        "# TODO: Falta consultar limites del GPU, para armar las dimensiones correctamente.\n",
        "dim_hilo = 256\n",
        "dim_bloque = numpy.int( (cantidad_N+dim_hilo-1) / dim_hilo )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "\n",
        "#TODO: Ojo, con los tipos de las variables en el kernel.\n",
        "kernel( numpy.int32(cantidad_N),numpy.float32(alfa), x_gpu, y_gpu, block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n",
        "\n",
        "tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "# GPU - Copio el resultado desde la memoria GPU.\n",
        "cuda.memcpy_dtoh( r_cpu, y_gpu )\n",
        "\n",
        "\"\"\"\n",
        "# CPU - Informo el resutlado.\n",
        "print( \"------------------------------------\")\n",
        "print( \"X: \" )\n",
        "print( x_cpu )\n",
        "print( \"------------------------------------\")\n",
        "print( \"Y: \" )\n",
        "print( y_cpu )\n",
        "print( \"------------------------------------\")\n",
        "print( \"R: \" )\n",
        "print( r_cpu )\n",
        "\"\"\"\n",
        "\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "print( \"Cantidad de elementos: \", cantidad_N )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread x:  256 , Bloque x: 196\n",
            "Cantidad de elementos:  50000\n",
            "Thread x:  256 , Bloque x: 196\n",
            "Tiempo CPU:  2188.911 [ms]\n",
            "Tiempo GPU:  0.612 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iJ73IQkLKj7"
      },
      "source": [
        "#Ejercicio 1\n",
        "\n",
        "\n",
        "*   Elemento de la lista\n",
        "*   Elemento de la lista\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPXH2BZbKzRC"
      },
      "source": [
        "def mergeSort(myList):\n",
        "    if len(myList) > 1:\n",
        "        mid = len(myList) // 2\n",
        "        left = myList[:mid]\n",
        "        right = myList[mid:]\n",
        "\n",
        "        # Recursive call on each half\n",
        "        mergeSort(left)\n",
        "        mergeSort(right)\n",
        "\n",
        "        # Two iterators for traversing the two halves\n",
        "        i = 0\n",
        "        j = 0\n",
        "        \n",
        "        # Iterator for the main list\n",
        "        k = 0\n",
        "        \n",
        "        while i < len(left) and j < len(right):\n",
        "            if left[i] < right[j]:\n",
        "              # The value from the left half has been used\n",
        "              myList[k] = left[i]\n",
        "              # Move the iterator forward\n",
        "              i += 1\n",
        "            else:\n",
        "                myList[k] = right[j]\n",
        "                j += 1\n",
        "            # Move to the next slot\n",
        "            k += 1\n",
        "\n",
        "        # For all the remaining values\n",
        "        while i < len(left):\n",
        "            myList[k] = left[i]\n",
        "            i += 1\n",
        "            k += 1\n",
        "\n",
        "        while j < len(right):\n",
        "            myList[k]=right[j]\n",
        "            j += 1\n",
        "            k += 1\n",
        "\n",
        "myList = [54,26,93,17,77,31,44,55,20]\n",
        "mergeSort(myList)\n",
        "print(myList)\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "arr = np.round([random.uniform(1,10) for _ in range(1000)], decimals=2)\n",
        "\n",
        "\n",
        "def bubbleSort(arr): \n",
        "    n = len(arr) \n",
        "\n",
        "    for i in range(n-1): \n",
        "        for j in range(0, n-i-1): \n",
        "            if arr[j] > arr[j+1] : \n",
        "                arr[j], arr[j+1] = arr[j+1], arr[j] \n",
        "  \n",
        "  \n",
        "bubbleSort(arr) \n",
        "print(arr)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFfBjyXC1-70"
      },
      "source": [
        "#Referencias\n",
        "\n",
        "\n",
        "*   https://dergipark.org.tr/en/download/article-file/225714\n",
        "*   https://github.com/master-hpc\n",
        "* https://docs.nvidia.com/cuda/cuda-math-api/group__CUDA__MATH__SINGLE.html#group__CUDA__MATH__SINGLE\n"
      ]
    }
  ]
}