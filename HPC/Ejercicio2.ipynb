{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejercicio2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP7qF4bvR9U+CVf7hqa11Jz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablobermudez/Up/blob/main/HPC/Ejercicio2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp_pYMDMmNOG"
      },
      "source": [
        "#1 Introducción\n",
        "\n",
        "Este ejercicio poseerá una multiplicación de matrices realizada con dos implementaciones diferentes: la primera utilizando solamente el lenguaje Python y la segunda haciendo uso del GPU con el lenguaje Python y Cuda junto con el framework pycuda.\n",
        "\n",
        "Su finalidad, además de demostrarnos las diferencias en los tiempos de ejecución según el tamaño de las matrices ingresadas, será el der comprender como Cuda hace uso del manejo de su ejecución en paralelo de hilos para modificar y simplificar lo que sería un algoritmo de multiplicación de matrices como lo solemos hacer en otro tipo de lenguaje.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtEUlCEfmQLB"
      },
      "source": [
        "#2 Armado del ambiente\n",
        "\n",
        "Instalar en el cuaderno el módulo CUDA de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZFBIadQpcz1"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toqvXvwmmSqT"
      },
      "source": [
        "#3 Desarrollo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yGyhPNypLzg"
      },
      "source": [
        "##3.1 Desarrollo - CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5AeCSRQmUVq",
        "outputId": "418189bd-f8ea-4053-af7e-52c11cf51635"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "Filas_Matriz_A =   2#@param {type: \"number\"}\n",
        "Columnas_Matriz_B = 3#@param {type: \"number\"}\n",
        "Filas_B_Columnas_A = 1#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "# --------------------------------------------\n",
        "# Valido número de ingreso por el usuario\n",
        "if (Filas_B_Columnas_A <= 0 or Filas_Matriz_A < 0 or Columnas_Matriz_B < 0 ):\n",
        "  raise Exception(\"Por favor, no ingrese números negativos. El atributo Filas_B_Columnas_A no puede ser igual a 0\") \n",
        "# --------------------------------------------\n",
        "\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "\n",
        "# --------------------------------------------\n",
        "# Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "# CPU - Genero las matrices segun los parametros\n",
        "X = np.random.randint(0, 100, (Filas_Matriz_A, Filas_B_Columnas_A))\n",
        "Y = np.random.randint(0, 100, (Filas_B_Columnas_A, Columnas_Matriz_B))\n",
        "result = np.zeros((Filas_Matriz_A,Columnas_Matriz_B), dtype=int)\n",
        "\n",
        "for i in range(len(X)):\n",
        "   for j in range(len(Y[0])):\n",
        "       for k in range(len(Y)):\n",
        "           result[i][j] += X[i][k] * Y[k][j]\n",
        "\n",
        "print( \"Resultados:\" )\n",
        "print( \"------------------------------------\")\n",
        "print(\"Matriz X: \")\n",
        "for x in X:\n",
        "   print(x)\n",
        "print()\n",
        "print(\"Matriz Y: \")\n",
        "for y in Y:\n",
        "   print(y)   \n",
        "print()\n",
        "print(\"Matriz resultante: \")\n",
        "for r in result:\n",
        "   print(r)\n",
        "print( \"------------------------------------\")\n",
        "\n",
        "print()\n",
        "print( \"Tiempos: \" )\n",
        "print( \"------------------------------------\")\n",
        "# CPU - Informo tiempos, hilos y bloques.\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print( \"------------------------------------\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resultados:\n",
            "------------------------------------\n",
            "Matriz X: \n",
            "[92]\n",
            "[87]\n",
            "\n",
            "Matriz Y: \n",
            "[13 97 63]\n",
            "\n",
            "Matriz resultante: \n",
            "[1196 8924 5796]\n",
            "[1131 8439 5481]\n",
            "------------------------------------\n",
            "\n",
            "Tiempos: \n",
            "------------------------------------\n",
            "Tiempo CPU:  2.877 [ms]\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p12sHS6L6DSq"
      },
      "source": [
        "##![Important symbol](https://drive.google.com/uc?id=1AWRLAqeaqi7SG7PHyOVywZRuMDK9Z2_s)**Importante:** Debe cambiar de entorno de ejecución a GPU para poder ejecutar el siguiente desarrollo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3B8r3vKpqLC"
      },
      "source": [
        "##3.2 Desarrollo - GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDRxRd0CpwhT",
        "outputId": "283ccaf2-ad63-4d45-c950-c6515f08744a"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.2.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "Filas_Matriz_A =   3#@param {type: \"number\"}\n",
        "Columnas_Matriz_B = 5#@param {type: \"number\"}\n",
        "Filas_B_Columnas_A = 1#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "# --------------------------------------------\n",
        "# Valido número de ingreso por el usuario\n",
        "if (Filas_B_Columnas_A <= 0 or Filas_Matriz_A < 0 or Columnas_Matriz_B < 0 ):\n",
        "  raise Exception(\"Por favor, no ingrese números negativos. El atributo Filas_B_Columnas_A no puede ser igual a 0\") \n",
        "# --------------------------------------------\n",
        "\n",
        "# --------------------------------------------\n",
        "# Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "# --------------------------------------------\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "from datetime import datetime\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "n = 4\n",
        "ni = np.int32(n)\n",
        "\n",
        "# CPU - Defino la memoria de los vectores en cpu.\n",
        "a = np.random.randint(0, 100, (n, n))\n",
        "a = a.astype(np.int32())\n",
        "\n",
        "print(\"Matriz X: \")\n",
        "for aa in a:\n",
        "   print(aa)\n",
        "\n",
        "b = np.random.randint(0, 100, (n, n))\n",
        "b = b.astype(np.int32)\n",
        "\n",
        "print(\"Matriz Y: \")\n",
        "for bb in b:\n",
        "   print(bb)\n",
        "\n",
        "c = np.zeros((n,n), dtype=int)\n",
        "c = c.astype(np.int32)\n",
        "\n",
        "# CPU - reservo la memoria GPU.\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "\n",
        "# GPU - Copio la memoria al GPU.\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "cuda.memcpy_htod(b_gpu, b)\n",
        "\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void matmul(int n, const float *A, const float *B, float *C){\n",
        "\n",
        "  int tx = threadIdx.x;\n",
        "  int ty = threadIdx.y;\n",
        "\n",
        "  int bx = blockIdx.x;\n",
        "  int by = blockIdx.y;\n",
        "\n",
        "  int row = by*blockDim.y + ty;\n",
        "  int col = bx*blockDim.x + tx;\n",
        "\n",
        "  //Validamos que los hilos que no se encuentren dentro de las posiciones de memoria de las matrices no realizen ninguna tarea.\n",
        "  if(row < n && col < n){\n",
        "    float val = 0.0;\n",
        "    for(int i=0; i<n; ++i){\n",
        "      val += A[row*n + i]*B[n*i + col];\n",
        "    }\n",
        "    C[row*n + col] = val;\n",
        "  }\n",
        "}\n",
        "\n",
        "\"\"\") \n",
        "\n",
        "# CPU - Genero la función kernel.\n",
        "kernel = module.get_function(\"matmul\")\n",
        "tiempo_gpu = datetime.now()\n",
        "\n",
        "dim_hilo_x = 16\n",
        "dim_bloque_x = np.int( (4+dim_hilo_x-1) / dim_hilo_x )\n",
        "\n",
        "dim_hilo_y = 16\n",
        "dim_bloque_y = np.int( (4+dim_hilo_y-1) / dim_hilo_y )\n",
        "\n",
        "# GPU - Ejecuta el kernel.\n",
        "kernel(np.int32(ni), a_gpu, b_gpu, c_gpu, block=( dim_hilo_x, dim_hilo_y, 1 ), grid=(dim_bloque_x, dim_bloque_y,1));\n",
        "tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "# GPU - Copio el resultado desde la memoria GPU.\n",
        "cuda.memcpy_dtoh(c, c_gpu)\n",
        "\n",
        "print( \"Resultados:\" )\n",
        "print( \"------------------------------------\")\n",
        "\n",
        "print (c)\n",
        "\n",
        "print( \"------------------------------------\")\n",
        "\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "print()\n",
        "print( \"Tiempos: \" )\n",
        "print( \"------------------------------------\")\n",
        "# TODO - Informo tiempos, hilos y bloques.\n",
        "print( \"Thread x: \", dim_hilo_x, \", Bloque x:\", dim_bloque_x )\n",
        "print( \"Thread y: \", dim_hilo_y, \", Bloque y:\", dim_bloque_y )\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\") \n",
        "print( \"------------------------------------\")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz X: \n",
            "[62 41 45 38]\n",
            "[74 41 16 44]\n",
            "[33 67  8 59]\n",
            "[59 31 54 54]\n",
            "Matriz Y: \n",
            "[85 86 84 13]\n",
            "[14 44 22  4]\n",
            "[81 10 35 79]\n",
            "[30 36 76 21]\n",
            "Thread x:  16 , Bloque x: 1\n",
            "Thread y:  16 , Bloque y: 1\n",
            "Resultados:\n",
            "------------------------------------\n",
            "<pycuda._driver.DeviceAllocation object at 0x7f078eea6da0>\n",
            "------------------------------------\n",
            "\n",
            "Tiempos: \n",
            "------------------------------------\n",
            "Thread x:  256 , Bloque x: 1\n",
            "Tiempo CPU:  5.134 [ms]\n",
            "Tiempo GPU:  0.686 [ms]\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_JhYZEimUr0"
      },
      "source": [
        "#4 Tabla de pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOQ-_MU5-K6Q"
      },
      "source": [
        "##4.1 Tabla de pasos - CPU\n",
        "\n",
        " Procesador | Función | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura de los parametros necesarios para la generación de las matrices.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  raise Exception()     | Lanza una exception.\n",
        "CPU      |  np.random.randint() | Inicializa las matrices con valores random de tipo entero según los parametros recibidos.\n",
        "CPU      |  np.zeros()      | Inicializa la matriz que contendrá el resultado según los parámetros ingresados con el valor 0 en sus posiciones.\n",
        "CPU      |  range()               | Genera una secuencia de valores enteros según los valores que recibe.\n",
        "CPU      |  print()               | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpKWUKPZAPS1"
      },
      "source": [
        "##4.2 Tabla de pasos - GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXHbDgQPmY-l"
      },
      "source": [
        "#5 Conclusiones\n",
        "\n",
        "[1] Las matrices generadas, que son poseen dos dimensiones, se almacenan en memoria en una sola dimensión siendo posible obtener el valor de una matriz como si fuese un vector realizando un sencillo cálculo para obtener la posición de memoria de la matriz y el valor que este contiene. Este hecho, hace que no tengamos que realizar varios ciclos en Cuda para poder acceder al valor de la matriz como si realizamos en Python.\n",
        "\n",
        "[2] Cada hilo será el encargado de calcular el valor de uno de los valores de la matriz resultante, esto quiere decir que se generarán tantos hilos como posiciones posea la matriz resultante.\n",
        "\n",
        "Como vemos, a diferencia del ejercicio 1 donde se debían sincronizar los hilos para que puedan realizar un ordenamiento óptimo, este tipo de algoritmo no posee tal desventaja ya que puede calcular cada valor de la matriz resultante sin necesidad de una sincronización con todos los demás. Esto le asigna a la implementación de este algoritmo con la ayuda del GPU muchas ventajas en relación a una versión que solo utiliza CPU.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2GxLMXCmaio"
      },
      "source": [
        "#6 Referencias\n",
        "\n",
        "\n",
        "\n",
        "*   [1] https://www.tutorialspoint.com/cuda/cuda_matrix_multiplication.htm\n",
        "*   [2] https://www.fz-juelich.de/SharedDocs/Downloads/IAS/JSC/EN/slides/cuda/05-cuda-mm.pdf?__blob=publicationFile\n",
        "\n"
      ]
    }
  ]
}