{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejercicio1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cUOT0TsOoDzz",
        "WxAHGanvpPnI",
        "ai2DT1HitKMn"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablobermudez/Up/blob/main/HPC/Ejercicio1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf1PpWeeTcoI"
      },
      "source": [
        "# 1 Introducción\n",
        "\n",
        "El ejercicio posee dos versiones del algoritmo de ordenamiento denominado **Bubble Sort**, la primera de ellas deberá ejecutarse en el entorno CPU con el lenguaje Python y la segunda en el entorno GPU utilizando el lenguaje Cuda junto con la librería pycuda.\n",
        "\n",
        "La finalidad del ejercicio no es centrarse en la complejidad del algoritmo utilizado, sino en la información que nos provee y en el sustento teórico que poseen y en las diferencias que presenta el mismo al ejecutarse en entorno **CPU** y **GPU**.\n",
        "\n",
        "Se medirán los tiempos que demora la ejecución en ambos ambientes, y se hará foco en porque es necesario modificar sus implementaciones más allá del lenguaje de programación utilizado.\n",
        "\n",
        "Para entender mejor lo mencionado, ejecutaremos las pruebas y veremos entonces las conclusiones.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUOT0TsOoDzz"
      },
      "source": [
        "#2 Armado del ambiente\n",
        "Instalar en el cuaderno el módulo CUDA de Python.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eceh5yt8oQ1y"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF7PJHXNb1k7"
      },
      "source": [
        "#3 Desarrollo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxAHGanvpPnI"
      },
      "source": [
        "##3.1 Desarrollo - CPU\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTlmmqpspVZY"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "cantidad_N =   0#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "# --------------------------------------------\n",
        "# Valido número de ingreso por el usuario\n",
        "if (cantidad_N <= 0):\n",
        "  raise Exception(\"Solo se aceptan números positivos\") \n",
        "# --------------------------------------------\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from datetime import datetime\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "\n",
        "# --------------------------------------------\n",
        "# Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "# --------------------------------------------\n",
        "# Defino variables\n",
        "arr = [random.randint(1,10) for _ in range(cantidad_N)]\n",
        "\n",
        "\n",
        "# Defino algoritmo\n",
        "def bubbleSort(arr): \n",
        "    n = len(arr) \n",
        "    for i in range(n-1): \n",
        "        for j in range(0, n-i-1): \n",
        "            if arr[j] > arr[j+1] : \n",
        "                arr[j], arr[j+1] = arr[j+1], arr[j] \n",
        "\n",
        "# Ejecuto ordenamiento\n",
        "bubbleSort(arr) \n",
        "\n",
        "\n",
        "# CPU - Informo tiempos, hilos y bloques.\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "\n",
        "# CPU - Informo el resutlado.\n",
        "print( \"------------------------------------\")\n",
        "print( \"Array: \" )\n",
        "print( arr )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5OvWwlCM413"
      },
      "source": [
        "##![Important symbol](https://drive.google.com/uc?id=1AWRLAqeaqi7SG7PHyOVywZRuMDK9Z2_s)**Importante:** Debe cambiar de entorno de ejecución a GPU para poder ejecutar el siguiente desarrollo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai2DT1HitKMn"
      },
      "source": [
        "##3.2 Desarrollo - GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds_geZIJtLtI"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.2.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "cantidad_N =   300#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "# --------------------------------------------\n",
        "# Valido número de ingreso por el usuario\n",
        "if (cantidad_N <= 0):\n",
        "  raise Exception(\"Solo se aceptan números positivos\") \n",
        "# --------------------------------------------\n",
        "\n",
        "import sys\n",
        "import random\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n",
        "from datetime import datetime\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --------------------------------------------\n",
        "# Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "# CPU - Defino la memoria de los vectores en cpu.\n",
        "x_cpu = [random.randint(1,10) for _ in range(cantidad_N)]\n",
        "x_cpu = np.array(x_cpu, dtype=np.int32)\n",
        "r_cpu = np.empty_like( x_cpu )\n",
        "\n",
        "# CPU - reservo la memoria GPU.\n",
        "x_gpu = cuda.mem_alloc( x_cpu.nbytes )\n",
        "\n",
        "# GPU - Copio la memoria al GPU.\n",
        "cuda.memcpy_htod( x_gpu, x_cpu )\n",
        "\n",
        "# CPU - Defino la función kernel que ejecutará en GPU.\n",
        "module = SourceModule(\"\"\"\n",
        "\n",
        "#include <stdio.h>\n",
        "__global__ void bubble_sort_gpu( int n, float *X)\n",
        "{\n",
        "\n",
        "   int i = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "   float aux;\n",
        "    for (int p = 0; p < n; ++p) {\n",
        "        if ((i - p) % 2 && i < n - 1 && X[i] > X[i + 1]) {\n",
        "            aux = X[i];\n",
        "            X[i] = X[i + 1];\n",
        "            X[i + 1] = aux;\n",
        "        }     \n",
        "        __syncthreads();\n",
        "    }\n",
        "}\n",
        "\n",
        "\"\"\") \n",
        "# CPU - Genero la función kernel.\n",
        "kernel = module.get_function(\"bubble_sort_gpu\")\n",
        "tiempo_gpu = datetime.now()\n",
        "\n",
        "# GPU - Ejecuta el kernel.\n",
        "dim_hilo = 256\n",
        "dim_bloque = np.int( (cantidad_N+dim_hilo-1) / dim_hilo )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "\n",
        "kernel( np.int32(cantidad_N), x_gpu, block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n",
        "tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "# GPU - Copio el resultado desde la memoria GPU.\n",
        "cuda.memcpy_dtoh( r_cpu, x_gpu )\n",
        "\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "# TODO - Informo tiempos, hilos y bloques.\n",
        "print( \"Cantidad de elementos: \", cantidad_N )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )\n",
        "\n",
        "# CPU - Informo el resutlado.\n",
        "print( \"------------------------------------\")\n",
        "print( \"X: \" )\n",
        "print( x_cpu )\n",
        "print( \"------------------------------------\")\n",
        "print( \"R: \" )\n",
        "print( r_cpu )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR5Tly6ybsB5"
      },
      "source": [
        "# 4 Tabla de pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlJNPDXheHGn"
      },
      "source": [
        "##4.1 Tabla de Pasos - CPU\n",
        "\n",
        " Procesador | Función | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tamaño de vectores desde Colab.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  raise Exception()     | Lanza una exception.\n",
        "CPU      |  random.randint(1,10) for _ in range(cantidad_N) | Inicializa el vector **arr** con cantidad_N de números random entre el 1 y el 10.\n",
        "CPU      |  bubbleSort(arr)      | Ordena el vector con burbujeo.\n",
        "CPU      |  print()               | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hnMgVSjbeXB"
      },
      "source": [
        "##4.2 Tabla de Pasos - GPU\n",
        "\n",
        " Procesador | Funciòn | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tamaño de vectores desde Colab.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  raise Exception()     | Lanza una exception.\n",
        "CPU      |  random.randint(1,10) for _ in range(cantidad_N) | Inicializa el vector **x_cpu** con cantidad_N de números random entre el 1 y el 10.\n",
        "CPU      |  np.array()            | Defino los valores dentro del array **x_cpu** como int32.\n",
        "CPU      |  np.empty_like( **x_cpu** ) | Genera un array vacio del mismo tipo que **x_cpu** y se lo asigna a **r_cpu**.\n",
        "**GPU**  |  cuda.mem_alloc()      | Reserva la memoria en GPU.\n",
        "**GPU**  |  cuda.memcpy_htod()    | Copia las memorias desde el CPU al GPU.\n",
        "**GPU**  |  __syncthreads()       | Sincroniza los hilos de los distintos bloques para que puedan realizar la tarea de ordenamiento correctamente.\n",
        "CPU      |  SourceModule()        | Define el código del kernel. \n",
        "CPU      |  module.get_function() | Genera la función del kernel GPU.\n",
        "CPU      |  dim_tx/dim_bx         | Calcula las dimensiones.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU.\n",
        "CPU      |  cuda.memcpy_dtoh( )   | Copia el resultado desde GPU memoria A a CPU memoria R.\n",
        "CPU      |  print()               | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKBi0xBGejka"
      },
      "source": [
        "#5 Conclusiones\n",
        "\n",
        "Notamos al ejecutar ambas pruebas, que cuando nuestra variable **cantidad_N** corresponde a valores numéricos grandes, la implementación realizada en conjunto con el procesador GPU da una clara ventaja utilizando su paralelismo y logra tiempos mucho más cortos para realizar el ordenamiento.\n",
        "\n",
        "Este hecho, no implica que el Bubble Sort sea un algoritmo ideal para delegarlo al GPU ya que este deberá realizar muchas operaciones extras para poder sincronizar los hilos ejecutados y esto llevará un tiempo considerable.[2] Un algoritmo de ordenamiento mas idóneo para realizar con ayuda del GPU sería algún algoritmo de ordenamiento del tipo \"divide y vencerás\" cuya naturaleza le permite no tener que forzar la sincronización de todos los hilos ejecutados.\n",
        "\n",
        "[1]La complejidad computacional del algoritmo Bubble Sort en el peor de los casos corresponde a O(n*n) ejecutándose en CPU, mientras que se considera que, si el mismo es ejecutado con ayuda del GPU, esta complejidad computacional disminuye considerablemente al orden de O(n*n/p) siendo p el número de hilos ejecutados.\n",
        "\n",
        "Como posibilidad de expandir este ejercicio, se podría implementar en paralelo otro algoritmo de ordanmiento del tipo QuickSort o MergeSort para hacer más notorias las diferencias de implementación con el framework pycuda.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFfBjyXC1-70"
      },
      "source": [
        "# 6 Referencias\n",
        "\n",
        "\n",
        "*   [1] https://dergipark.org.tr/en/download/article-file/225714\n",
        "*   [2] https://arxiv.org/ftp/arxiv/papers/1505/1505.07605.pdf\n"
      ]
    }
  ]
}